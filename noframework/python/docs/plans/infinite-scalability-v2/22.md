# Task 22: CLI Implementation

## Objective
Implement the command-line interface for the tech writer.

## Dependencies
- Task 21: Report assembly

## Deliverables

`tech_writer/cli.py`:

```python
import argparse
from pathlib import Path

def main():
    parser = argparse.ArgumentParser(
        description="Generate technical documentation from codebases"
    )
    parser.add_argument(
        "--prompt", "-p",
        required=True,
        help="Path to prompt file or prompt string"
    )
    parser.add_argument(
        "--repo", "-r",
        required=True,
        help="Repository path or URL"
    )
    parser.add_argument(
        "--output", "-o",
        help="Output file path (default: stdout)"
    )
    parser.add_argument(
        "--model",
        default="openai/gpt-4o-mini",
        help="Model to use (default: openai/gpt-4o-mini)"
    )
    parser.add_argument(
        "--max-exploration",
        type=int,
        default=50,
        help="Max exploration steps (default: 50)"
    )
    parser.add_argument(
        "--max-sections",
        type=int,
        default=20,
        help="Max report sections (default: 20)"
    )
    parser.add_argument(
        "--persist-cache",
        action="store_true",
        help="Keep SQLite cache after run"
    )
    parser.add_argument(
        "--cache-path",
        help="Path for cache file (default: temp)"
    )
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="Verbose output"
    )

    args = parser.parse_args()
    run(args)
```

## Acceptance Criteria

- [ ] `python -m tech_writer --help` shows usage
- [ ] Accepts prompt as file path or string
- [ ] Accepts repo as local path or URL
- [ ] Outputs to file or stdout
- [ ] Supports model selection
- [ ] Respects max-exploration and max-sections
- [ ] Cache is cleaned up by default
- [ ] Verbose mode shows progress

## Test Cases

```gherkin
Feature: CLI interface

  Scenario: Basic usage
    Given a prompt file "prompt.md"
    And a local repository "/path/to/repo"
    When I run: python -m tech_writer --prompt prompt.md --repo /path/to/repo
    Then a report should be generated
    And output should go to stdout

  Scenario: Output to file
    When I run: python -m tech_writer -p prompt.md -r /path/to/repo -o report.md
    Then report should be written to report.md

  Scenario: Remote repository
    When I run: python -m tech_writer -p prompt.md -r https://github.com/axios/axios
    Then the repo should be cloned
    And exploration should proceed

  Scenario: Help text
    When I run: python -m tech_writer --help
    Then usage information should be displayed
    And all options should be documented

  Scenario: Missing required args
    When I run: python -m tech_writer --prompt prompt.md
    Then an error should indicate --repo is required
```

## Usage Examples

```bash
# Basic usage with local repo
python -m tech_writer \
  --prompt prompts/architecture-overview-lite.prompt.txt \
  --repo ./my-project

# Remote repo with output file
python -m tech_writer \
  --prompt prompts/architecture-overview-lite.prompt.txt \
  --repo https://github.com/axios/axios \
  --output axios-architecture.md

# With options
python -m tech_writer \
  --prompt "Explain the authentication system" \
  --repo ./my-project \
  --model openai/gpt-4o \
  --max-exploration 30 \
  --verbose

# Persist cache for debugging
python -m tech_writer \
  --prompt prompt.md \
  --repo ./my-project \
  --persist-cache \
  --cache-path ./debug-cache.db
```

## Implementation Notes

- Use `argparse` for argument parsing
- Read prompt from file if path exists, else treat as string
- Defer repo cloning to task 23
- Create Store with temp path or specified path
- Clean up cache on exit unless --persist-cache
- Use logging for verbose output
