# Task 10: CLI Integration

## Design Reference
- [eval.md ยง CLI Integration](../eval.md)

## Objective
Add evaluation flags to tech_writer CLI.

## Requirements

### R10.1: Eval Flag
`--eval` runs evaluation after report generation

### R10.2: Eval Mode Options
- `--eval-structural`: Run only structural checks (no LLM)
- `--eval-full`: Run full evaluation including LLM judge

### R10.3: Threshold Override
- `--eval-threshold-validity=0.95`
- `--eval-threshold-precision=0.80`
- `--eval-threshold-coverage=0.50`

### R10.4: Output Format
- Default: Human-readable to stderr
- `--eval-json`: Machine-readable JSON output
- `--eval-fail-fast`: Exit code 2 on eval failure

### R10.5: Cost Reporting
Show LLM calls and tokens used

## Dependencies
- Task 9: Aggregation (provides `EvalResult`)

## Test Plan

| Test | Command | Expected |
|------|---------|----------|
| Basic eval | `--eval` | Metrics printed to stderr |
| Structural only | `--eval-structural` | No LLM calls |
| JSON output | `--eval --eval-json` | JSON to stdout |
| Fail fast | `--eval --eval-fail-fast` | Exit 2 on failure |
| Custom threshold | `--eval-threshold-precision=0.9` | Uses custom threshold |

## Acceptance Criteria
- [ ] `--eval` flag works with report generation
- [ ] Output goes to stderr (report to stdout/file)
- [ ] JSON output is valid and complete
- [ ] Exit codes: 0=pass, 1=error, 2=eval failure
- [ ] `--help` documents all eval options
