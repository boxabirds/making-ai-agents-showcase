# Task 7: LLM Batching

## Design Reference
- [tech-design.md ยง5.3](../../design/citation-eval/tech-design.md#53-batching-strategy)

## Objective
Batch multiple abstractive verification requests to reduce LLM API calls and cost.

## Requirements

### R7.1: Grouping Strategy
Group citations by:
- Same source file (likely related context)
- Up to 5 claims per batch (per tech-design.md ยง5.3)

### R7.2: Batch Prompt Format
Per tech-design.md ยง5.3:
- Enumerate claims with IDs
- Include code for each
- Request JSON array response

### R7.3: Response Disaggregation
Map batch response back to individual citations

### R7.4: Error Handling
If batch fails:
- Retry once with smaller batch
- Fall back to individual calls

## Dependencies
- Task 6: Abstractive verification (single-claim implementation)

## Test Plan

| Test | Input | Expected |
|------|-------|----------|
| Single batch | 3 claims, same file | 1 LLM call |
| Multiple batches | 12 claims | 3 LLM calls (batches of 5,5,2) |
| Cross-file | 6 claims, 3 files | 3 LLM calls (grouped by file) |
| Batch failure | LLM returns invalid JSON | Retry, then individual fallback |
| Empty batch | 0 claims | 0 LLM calls |

## Acceptance Criteria
- [ ] Reduces LLM calls by ~5x for typical reports
- [ ] Grouping by file implemented
- [ ] Batch size configurable
- [ ] Error recovery works
- [ ] Token usage tracked across batches
