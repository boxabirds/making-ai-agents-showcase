# Task 9: Aggregation & Metrics

## Design Reference
- [tech-design.md §3.2.6](../../design/citation-eval/tech-design.md#326-stage-5-aggregation)
- [tech-design.md §8.6](../../design/citation-eval/tech-design.md#86-evalresult)

## Objective
Compute final metrics and populate failed citations list from verification results.

## Requirements

### R9.1: Validity Rate
`valid_citations / total_citations`

### R9.2: Precision Metrics
Per tech-design.md §3.2.6:
- Extractive precision: `extractive_supports / extractive_total`
- Abstractive precision: `abstractive_supports / abstractive_total`
- Overall precision: `all_supports / all_checked`

### R9.3: Coverage
`cited_claims / total_claims`

### R9.4: Cost Metrics
- LLM calls made
- Total tokens used

### R9.5: Failed Citations List
Per tech-design.md §8.6:
- Populate `failed_citations: list[FailedCitation]`
- Set `needs_correction` property (True if any failures)
- Set `is_perfect` property (True if 100% valid and supporting)

> **Note:** No threshold-based pass/fail. Target is 100% accuracy.
> All failures feed into correction workflow (Task 14).

## Dependencies
- Task 8: Pipeline orchestration (provides raw results)

## Test Plan

| Test | Input | Expected |
|------|-------|----------|
| Perfect score | All valid, all support | validity=1.0, precision=1.0, is_perfect=True |
| Mixed results | 8/10 valid, 6/8 support | validity=0.8, precision=0.75, needs_correction=True |
| No abstractive | Only extractive claims | abstractive_precision=N/A |
| Failures collected | 3 invalid citations | failed_citations has 3 items |
| Failure types | Various failure causes | Each FailedCitation has correct failure_type |

## Acceptance Criteria
- [ ] All metrics from tech-design.md §3.2.6 computed
- [ ] Division by zero handled (N/A for empty categories)
- [ ] `failed_citations` list populated with FailedCitation objects
- [ ] `needs_correction` and `is_perfect` properties work correctly
- [ ] `EvalResult` structure matches tech-design.md §8.6
