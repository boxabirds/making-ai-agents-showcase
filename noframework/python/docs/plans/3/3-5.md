# Task 3-5: Add context injection to LLM prompts

## Reference

See `docs/designs/3/tech-design.md` Â§Context Injection

## Requirements

1. **Exploration phase prompt**
   - Append complexity context to system prompt
   - Include bucket, guidance, budget limits

2. **Outline generation prompt**
   - Include complexity context
   - Mention hotspots to prioritize

3. **Section generation prompts**
   - Per-section budget awareness
   - Prioritization guidance for large codebases

## Context String Format

```
## Codebase Complexity Analysis

This is a **{bucket}** codebase ({total_cc:,} total cyclomatic complexity).

**Documentation Strategy**: {guidance}

**Complex Hotspots to Cover**:
  - {file}:{line} {name} (CC={cc})
  ...

**Budget**: Up to {max_sections} sections, {max_exploration} exploration steps.
```

## Testing Approach

- Verify context string appears in LLM messages
- Mock LLM to capture prompts

## Acceptance Criteria

- [ ] Context injected into exploration prompt
- [ ] Context injected into outline prompt
- [ ] Hotspots listed in context
