# smolagents API Usage for Creating a ReAct Agent with Tool Calling

This document provides an exhaustive guide on how to use the `smolagents` package API to create a ReAct agent with tool calling capabilities. It explains the relevant classes, their usage, and provides example code snippets to help you get started quickly.

---

## Table of Contents

- [Overview](#overview)
- [Key Classes for ReAct Agents](#key-classes-for-react-agents)
  - [MultiStepAgent (Base Class)](#multistepagent-base-class)
  - [ToolCallingAgent](#toolcallingagent)
  - [CodeAgent](#codeagent)
- [Creating Tools](#creating-tools)
- [Using ToolCallingAgent to Create a ReAct Agent with Tool Calling](#using-toolcallingagent-to-create-a-react-agent-with-tool-calling)
- [Example: Creating and Running a ToolCallingAgent](#example-creating-and-running-a-toolcallingagent)
- [Additional Features](#additional-features)
- [Summary](#summary)

---

## Overview

The `smolagents` package provides a framework to build multi-step agents that follow the ReAct (Reasoning + Acting) paradigm. These agents can interact with external tools or managed agents to perform complex tasks by iteratively generating actions and observing results.

Two main agent classes support tool calling:

- **ToolCallingAgent**: Uses JSON-like tool calls leveraging the LLM's native tool calling capabilities.
- **CodeAgent**: Uses code-formatted tool calls parsed and executed by a Python executor.

This document focuses on how to create a ReAct agent with tool calling using the `ToolCallingAgent` class.

---

## Key Classes for ReAct Agents

### MultiStepAgent (Base Class)

- Abstract base class for agents that solve tasks step-by-step using the ReAct framework.
- Manages tools, models, prompt templates, memory, logging, and execution flow.
- Supports streaming outputs and planning steps.
- Defines the core interface and lifecycle for agent execution.

**Key methods:**

- `run(task: str, stream: bool = False, ...)`: Run the agent on a given task.
- `write_memory_to_messages()`: Convert agent memory to messages for LLM input.
- `initialize_system_prompt()`: Abstract method to define the system prompt.
- `_step_stream()`: Abstract method to perform one step of the agent (to be implemented by subclasses).
- `execute_tool_call(tool_name, arguments)`: Execute a tool or managed agent call with arguments.

### ToolCallingAgent

- Subclass of `MultiStepAgent`.
- Uses the LLM's tool calling API (`model.get_tool_call`) to generate JSON-like tool calls.
- Supports streaming outputs if the model supports `generate_stream`.
- Automatically parses tool calls from the model output and executes the corresponding tool.
- Handles final answers via a special `final_answer` tool call.

**Constructor arguments:**

- `tools`: List of `Tool` instances the agent can use.
- `model`: The LLM model instance.
- `prompt_templates`: Optional prompt templates (defaults to `toolcalling_agent.yaml`).
- `planning_interval`: Optional interval for planning steps.
- `stream_outputs`: Whether to stream outputs during execution (default `False`).
- Additional keyword arguments passed to `MultiStepAgent`.

**Key methods:**

- `initialize_system_prompt()`: Populates the system prompt with tools and managed agents.
- `_step_stream(memory_step)`: Implements the ReAct step with tool calling and streaming.
- `execute_tool_call(tool_name, arguments)`: Executes the tool or managed agent with argument substitution.

### CodeAgent

- Another subclass of `MultiStepAgent`.
- Uses code-formatted tool calls generated by the LLM.
- Parses and executes code snippets using a Python executor (local, Docker, or remote).
- Supports structured outputs and streaming.
- More complex but flexible for code-based tool calls.

---

## Creating Tools

Tools are Python functions decorated with `@tool` from `smolagents`. These functions define the interface and logic for external capabilities the agent can call.

Example tool definition:

```python
from smolagents import tool

@tool
def get_weather(location: str, celsius: bool | None = False) -> str:
    """
    Get the current weather at the given location.

    Args:
        location: City name.
        celsius: Return temperature in Celsius if True, Fahrenheit otherwise.

    Returns:
        A string describing the current weather.
    """
    # Implementation here...
    return "Sunny, 25°C"
```

Tools must be passed as a list to the agent constructor.

---

## Using ToolCallingAgent to Create a ReAct Agent with Tool Calling

1. **Import necessary classes:**

```python
from smolagents import ToolCallingAgent, tool, InferenceClientModel
```

2. **Define your tools using the `@tool` decorator.**

3. **Instantiate your LLM model:**

```python
model = InferenceClientModel()
```

4. **Create the agent with the tools and model:**

```python
agent = ToolCallingAgent(
    tools=[get_weather, other_tools...],
    model=model,
    stream_outputs=True,  # Optional: enable streaming if supported
    planning_interval=5,  # Optional: run planning every 5 steps
)
```

5. **Run the agent on a task:**

```python
result = agent.run("What's the weather like in Paris?")
print(result)
```

---

## Example: Creating and Running a ToolCallingAgent

Below is a minimal example adapted from the package's examples:

```python
from smolagents import ToolCallingAgent, tool, InferenceClientModel

@tool
def get_weather(location: str, celsius: bool | None = False) -> str:
    return f"The weather in {location} is sunny and 25°C."

# Instantiate the model
model = InferenceClientModel()

# Create the agent with the tool and model
agent = ToolCallingAgent(
    tools=[get_weather],
    model=model,
    stream_outputs=True,
    verbosity_level=2,
)

# Run the agent on a query
print(agent.run("What's the weather like in Paris?"))
```

---

## Additional Features

- **Streaming:** If the model supports `generate_stream`, the agent can stream intermediate outputs.
- **Planning Steps:** The agent can run planning steps at intervals to update its plan.
- **Managed Agents:** The agent can call other managed agents as tools.
- **Saving and Loading:** Agents can be saved to disk or loaded from the HuggingFace Hub.
- **Logging and Visualization:** Rich logging and visualization of agent steps and memory.
- **Final Answer Validation:** Custom validation functions can be provided to check final answers.

---

## Summary

- Use `ToolCallingAgent` to create a ReAct agent that leverages LLM tool calling.
- Define tools as Python functions decorated with `@tool`.
- Provide a compatible LLM model instance.
- Instantiate the agent with tools and model, optionally enabling streaming and planning.
- Run the agent with `agent.run(task)` to get the final answer.
- The agent handles parsing tool calls, executing tools, and managing memory internally.

---

This concludes the detailed guide on using the `smolagents` API to create a ReAct agent with tool calling. For more advanced usage, refer to the `CodeAgent` class and the examples provided in the package.